**A basic ETL pipeline to read data from a source, transform this data, then load the output into a prescribed location.**
working with *7+ Million Companies dataset*, which has info about companies, company size, location, domain name etc.

**Final project includes**
- a python script with the following features; 
- Download the 7+ Million Dataset from S3 [bucket: blossom-data-engs key:-project1/free-7-million-company-dataset.zip].
- Read the file with pandas.
- Filted out all null values.
Available outputs in the following formats 
- Parquet
- JSON (compressed using gzip)


